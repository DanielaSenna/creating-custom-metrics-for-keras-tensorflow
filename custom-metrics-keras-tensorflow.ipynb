{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Criando Métricas Personalizadas Para Keras/Tensorflow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode implementar sua própria métrica e usá-la como objetivo e na busca de hiperparâmetros.\n",
    "\n",
    "\n",
    "Nesse notebook, iremos implementar com o Keras/Tensorflow duas métricas do Scikit-Learn para avaliar o desempenho de uma Rede Neural Convolucional (CNN):\n",
    "* F1-Score\n",
    "* Balanced Accuracy Score\n",
    "\n",
    "[Custom metric as the objective](https://keras.io/guides/keras_tuner/getting_started/#tune-model-training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Métricas Personalizadas**\n",
    "\n",
    "Se precisar de uma métrica que não faça parte da API Keras, você poderá criar facilmente métricas personalizadas criando uma subclasse da classe **keras.metrics.Metric**. Você precisará implementar 4 métodos:\n",
    "\n",
    "* **__init__(self)**, em que você criará variáveis ​​de estado para sua métrica. Todas as variáveis ​​de estado devem ser criadas neste método chamando self.add_variable() como: self.var = self.add_variable(...)\n",
    "* **update_state(self, y_true, y_pred, sample_weight=None)**, que usa os alvos y_true e as previsões do modelo y_pred para atualizar as variáveis ​​de estado. Possui todas as atualizações nas variáveis ​​de estado como: self.var.assign(...).\n",
    "* **result(self)**, que usa as variáveis ​​de estado para calcular os resultados finais. Calcula e retorna um valor escalar ou um ditado de valores escalares para a métrica das variáveis ​​de estado.\n",
    "* **reset_state(self)**, que reinicializa o estado da métrica.\n",
    "\n",
    "A atualização do estado e o cálculo dos resultados são mantidos separados (em update_state() e result(), respectivamente) porque, em alguns casos, o cálculo dos resultados pode ser muito caro e só seria feito periodicamente.\n",
    "\n",
    "[Custom Metrics](https://keras.io/guides/training_with_built_in_methods/)\n",
    "[Base Metric Class](https://keras.io/api/metrics/base_metric/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Importando as Bibliotecas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Classificação de Texto com Avaliações de Filmes**\n",
    "\n",
    "\n",
    "Este notebook classifica avaliações de filmes como positiva ou negativa usando o texto da avaliação. Isto é um exemplo de classificação binária —ou duas-classes—, um importante e bastante aplicado tipo de problema de aprendizado de máquina.\n",
    "\n",
    "Usaremos a base de dados IMDB que contém avaliaçòes de mais de 50000 filmes da base de dados Internet Movie Database. \n",
    "\n",
    "A base é dividida em 25000 avaliações para treinamento e 25000 para teste. Os conjuntos de **treinamentos e testes são balanceados**, ou seja, eles possuem a mesma quantidade de avaliações positivas e negativas.\n",
    "\n",
    "O notebook utiliza tf.keras, uma API alto-nível para construir e treinar modelos com TensorFlow\n",
    "\n",
    "[Text Classification Keras/Tensorflow](https://www.tensorflow.org/tutorials/keras/text_classification?hl=pt-br)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Baixe a base de dados IMDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A base de dados vem empacotada com TensorFlow. \n",
    "# Ela já vem pré-processada de forma que as avaliações (sequências de palavras) foram convertidas em sequências de inteiros, onde cada inteiro representa uma palavra específica no dicionário.\n",
    "# O argumento num_words=10000 mantém as 10000 palavras mais frequentes no conjunto de treinamento. As palavras mais raras são descartadas para preservar o tamanho dos dados de forma maleável.\n",
    "\n",
    "imdb = tf.keras.datasets.imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Conjunto de Treinamento e Teste**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training entries: 25000, labels: 25000\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "\n",
    "print(\"Training entries: {}, labels: {}\".format(len(train_data), len(train_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Explore os dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "# Vamos parar um momento para entender o formato dos dados. \n",
    "# O conjunto de dados vem pré-processado: cada exemplo é um array de inteiros representando as palavras da avaliação do filme. \n",
    "# Cada label é um inteiro com valor ou de 0 ou 1, onde 0 é uma avaliação negativa e 1 é uma avaliação positiva.\n",
    "# O texto das avaliações foi convertido para inteiros, onde cada inteiro representa uma palavra específica no dicionário. Isso é como se parece a primeira revisão:\n",
    "\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 189)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As avaliações dos filmes têm tamanhos diferentes. \n",
    "# O código abaixo mostra o número de palavras da primeira e segunda avaliação. \n",
    "# Sabendo que o número de entradas da rede neural tem que ser o mesmo também, temos que resolver isto mais tarde.\n",
    "\n",
    "len(train_data[0]), len(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "       ...,\n",
       "       list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 7750, 5, 4241, 18, 4, 8497, 2, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 2, 4, 3586, 2]),\n",
       "       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 8778, 2, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Prepare os Dados**\n",
    "\n",
    "As avaliações —os arrays de inteiros— devem ser convertidas em tensores (tensors) antes de alimentar a rede neural. Essa conversão pode ser feita de duas formas:\n",
    "\n",
    "* Converter os arrays em vetores de 0s e 1s indicando a ocorrência da palavra, similar com one-hot encoding. Por exemplo, a sequência [3, 5] se tornaria um vetor de 10000 dimensões, onde todos seriam 0s, tirando 3 e 5, que são 1s. Depois, faça disso a primeira camada da nossa rede neural — a Dense layer — que pode trabalhar com dados em ponto flutuante. Essa abordagem é intensa em relação a memória, logo requer uma matriz de tamanho num_words * num_reviews.\n",
    "\n",
    "* Alternativamente, podemos preencher o array para que todos tenho o mesmo comprimento, e depois criar um tensor inteiro de formato max_length * num_reviews. Podemos usar uma camada embedding capaz de lidar com o formato como a primeira camada da nossa rede.\n",
    "\n",
    "Nesse notebook, usaremos a segunda abordagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Já que as avaliações dos filmes devem ter o mesmo tamanho, usaremos a função pad_sequences para padronizar os tamanhos:\n",
    "\n",
    "# Um dicionário mapeando palavras em índices inteiros\n",
    "word_index = imdb.get_word_index()\n",
    "word_index[\"<PAD>\"] = 0\n",
    "\n",
    "train_data = tf.keras.preprocessing.sequence.pad_sequences(train_data,\n",
    "                                                        value=word_index[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=256)\n",
    "\n",
    "test_data = tf.keras.preprocessing.sequence.pad_sequences(test_data,\n",
    "                                                       value=word_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,   14,   22, ...,    0,    0,    0],\n",
       "       [   1,  194, 1153, ...,    0,    0,    0],\n",
       "       [   1,   14,   47, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   1,   11,    6, ...,    0,    0,    0],\n",
       "       [   1, 1446, 7079, ...,    0,    0,    0],\n",
       "       [   1,   17,    6, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agora, vamos olhar o tamanho dos exemplos:\n",
    "\n",
    "\n",
    "len(train_data[0]), len(train_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Criando um Conjunto de Validação**\n",
    "\n",
    "Quando treinamos. queremos checar a acurácia do modelo com os dados que ele nunca viu. \n",
    "\n",
    "Crie uma conjunto de validação tirando 10000 exemplos do conjunto de treinamento original. \n",
    "\n",
    "(Por que não usar o de teste agora? Nosso objetivo é desenvolver e melhorar (tunar) nosso modelo usando somente os dados de treinamento, depois usaremos o teste uma única vez para avaliar a previsão)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = train_data[:10000]\n",
    "X_train = train_data[10000:]\n",
    "\n",
    "y_valid = train_labels[:10000]\n",
    "y_train = train_labels[10000:]\n",
    "\n",
    "\n",
    "# Deixar no padrão \n",
    "X_test = test_data\n",
    "y_test = test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Construindo o Modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O formato de entrada é a contagem vocabulário usados pelas avaliações dos filmes (10000 palavras)\n",
    "vocab_size = 10000\n",
    "max_length = 16\n",
    "\n",
    "def build_model(metric):\n",
    "    # Configurando a arquitetura do modelo  \n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # --> Camada de Entrada\n",
    "    # Geralmente, todas as camadas no Keras precisam conhecer a forma de suas entradas para poder criar seus pesos\n",
    "    # Neste caso, você deve iniciar seu modelo passando um objeto Input para seu modelo, para que ele conheça sua forma de entrada desde o início\n",
    "    # Modelos construídos com um formato de entrada predefinido como esse sempre possuem pesos (mesmo antes de ver qualquer dado) e sempre possuem um formato de saída definido.\n",
    "    # Em geral, é uma prática recomendada sempre especificar antecipadamente o formato de entrada de um modelo Sequencial, se você souber o que é.\n",
    "    # Uma alternativa simples é apenas passar um argumento input_shape para sua primeira camada:\n",
    "    # Exemplo: model.add(tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=max_length, input_shape=(max_length,)))\n",
    "    # No entanto, o exemplo acima gera um warning: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "    # https://keras.io/guides/sequential_model/\n",
    "    # https://www.tensorflow.org/guide/keras/sequential_model?hl=pt-br\n",
    "    model.add(tf.keras.Input(shape=(max_length,)))\n",
    "\n",
    "    # Adicionando Camada de Incorporação - Transforma inteiros positivos (índices) em vetores densos de tamanho fixo.\n",
    "    model.add(tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=max_length))\n",
    "\n",
    "    # --> Camadas Intermediárias\n",
    "    # Adicionando Camada de Convolução\n",
    "    model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "\n",
    "    # Adicionando Camada de Pooling\n",
    "    model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "                                \n",
    "    # Adicionando Camada Totalmente Conectada\n",
    "    model.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.30))\n",
    "\n",
    "    # --> Camada de Saída                 \n",
    "    model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # Sumário do modelo\n",
    "    #model.summary()\n",
    "\n",
    "    # Configurando o modelo para treinamento\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(name='adam', learning_rate=0.001),   # O learning_rate padrão é 0.001 \n",
    "                    # Já que é um problema de classificação binário e o modelo tem como saída uma probabilidade usaremos a função loss \"binary_crossentropy\". A binary_crossentropy é a melhor função de loss para tratar probabilidades— ela mede a \"distância\" entre as distribuições de probabilidade, ou, no nosso caso, sobre a distribuição real e as previsões.\n",
    "                    loss=tf.keras.losses.BinaryCrossentropy(name='binary_crossentropy'), \n",
    "                    # Usaremos como métrica a binary_accuracy. Essa métrica é utilizada especificamente em problemas de classificação binária e calcula com que frequência as previsões correspondem aos rótulos binários.\n",
    "                    metrics=[metric])\n",
    "    \n",
    "    # Treinando o modelo\n",
    "    history = model.fit(x=X_train,\n",
    "                        y=y_train,\n",
    "                        epochs=2,\n",
    "                        batch_size=512,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_valid, y_valid))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 265ms/step - binary_accuracy: 0.5055 - loss: 0.6929 - val_binary_accuracy: 0.5084 - val_loss: 0.6878\n",
      "Epoch 2/2\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 267ms/step - binary_accuracy: 0.6153 - loss: 0.6736 - val_binary_accuracy: 0.7442 - val_loss: 0.5709\n"
     ]
    }
   ],
   "source": [
    "# Usando a métrica BinaryAccuracy\n",
    "metric = tf.keras.metrics.BinaryAccuracy(name='binary_accuracy')\n",
    "\n",
    "model = build_model(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# O y_valid é um array de 1 Dimensão com valores inteiros.\n",
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6851244 ],\n",
       "       [0.13516665],\n",
       "       [0.1812261 ],\n",
       "       ...,\n",
       "       [0.5847843 ],\n",
       "       [0.40633494],\n",
       "       [0.45188066]], dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# O y_pred é um array de 2 Dimensões com valores flutuantes, ou seja, com probabilidades das classes. \n",
    "# Precisamos transformar os valores flutuantes em inteiros e converter o array para 1D\n",
    "y_pred = model.predict(X_valid)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10000,), dtype=int32, numpy=array([1, 0, 0, ..., 1, 0, 0])>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iremos usar as funçãoes do Tensorflow, mas também é possível usar o numpy\n",
    "# 1) Arrendondar os valores do array\n",
    "# 2) Transformar o array de 2D para 1D\n",
    "# 3) Converter o tipo do array para int32\n",
    "y_pred = tf.cast(tf.reshape(tf.round(y_pred), -1), dtype='int32')\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10000,), dtype=int32, numpy=array([1, 0, 0, ..., 1, 0, 0])>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# O y_pred é um tensor do tipo int32.\n",
    "# Vamos converter o y_valid para tensor do tipo int32\n",
    "y_valid_tensor =  tf.cast(tf.convert_to_tensor(y_valid), dtype='int32')\n",
    "y_valid_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10000,), dtype=bool, numpy=array([ True, False, False, ...,  True, False, False])>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforma o array/tensor em valores booleanos [0, 1, 0, 1] -> [False, True, False, True]\n",
    "y_valid_bool = tf.keras.ops.cast(y_valid_tensor, \"bool\")\n",
    "y_pred_bool  = tf.keras.ops.cast(y_pred, \"bool\")\n",
    "\n",
    "y_valid_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10000,), dtype=int32, numpy=array([1, 0, 0, ..., 1, 0, 0])>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usaremos a função lógica \"and\" para verifica a quantidade de valores verdadeiros e falsos\n",
    "#  A    and    B       S\n",
    "# True       True  = True\n",
    "# False      False = False\n",
    "# True       True  = False\n",
    "# True       True  = False\n",
    "values = tf.keras.ops.logical_and(tf.keras.ops.equal(y_valid_bool, True), tf.keras.ops.equal(y_pred_bool, True))\n",
    "\n",
    "# Converte o array/tensor de booleanos para inteiros\n",
    "values = tf.keras.ops.cast(values, dtype='int32')\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4269"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcula a soma dos elementos nas dimensões de um tensor.\n",
    "tp = tf.reduce_sum(values).numpy()\n",
    "tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Criando a Métrica F1-Score Customizada (sem parâmetro) usando Keras/Tensorflow**\n",
    "\n",
    "O F1-Score é a média harmônica entre precisão (precision) e revocação (recall), sendo uma métrica útil para avaliar a performance de modelos de classificação, especialmente quando há uma classe desbalanceada.\n",
    "\n",
    "[f1-score-guide](https://www.v7labs.com/blog/f1-score-guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O Tensorflow 2 possui uma opção de configuração para executar funções \"avidamente\", o que permitirá obter valores do Tensor por meio do método .numpy(). \n",
    "# Para habilitar a execução antecipada, use o seguinte comando: tf.config.run_functions_eagerly(True)\n",
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1ScoreA(tf.keras.metrics.Metric): \n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1ScoreA, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.true_negatives = self.add_weight(name='tn', initializer='zeros')\n",
    "        self.false_positives = self.add_weight(name='fp', initializer='zeros')\n",
    "        self.false_negatives = self.add_weight(name='fn', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        \n",
    "        # O y_true é um array de 1 Dimensão com valores inteiros.\n",
    "        # O y_pred é um array de 2 Dimensões com valores flutuantes, ou seja, com probabilidades das classes. \n",
    "        # Precisamos transformar o y_pred em inteiros e converter o array para 1D\n",
    "        # Iremos usar as funçãoes do Tensorflow\n",
    "        # 1) Arrendondar os valores do array\n",
    "        # 2) Transformar o array de 2D para 1D\n",
    "        # 3) Converter o tipo do array para int32\n",
    "        y_pred = tf.cast(tf.reshape(tf.round(y_pred), -1), dtype='int32')\n",
    "\n",
    "        # O y_pred é um tensor do tipo int32.\n",
    "        # Vamos converter o y_true para tensor do tipo int32\n",
    "        y_true = tf.cast(tf.convert_to_tensor(y_true), dtype='int32')\n",
    "\n",
    "        # Transforma o array em valores booleanos [0, 1, 0, 1] -> [False, True, False, True]\n",
    "        y_true = tf.keras.ops.cast(y_true, \"bool\")\n",
    "        y_pred = tf.keras.ops.cast(y_pred, \"bool\")\n",
    "\n",
    "        # Verifica a quantidade de VERDADEIROS POSITIVOS (TP)\n",
    "        # Usaremos a função lógica \"and\" para verifica a quantidade de valores verdadeiros e falsos\n",
    "        #  A    and    B       S\n",
    "        # True       True  = True\n",
    "        # False      False = False\n",
    "        # True       True  = False\n",
    "        # True       True  = False\n",
    "        values = tf.keras.ops.logical_and(tf.keras.ops.equal(y_true, True), tf.keras.ops.equal(y_pred, True))\n",
    "        values = tf.keras.ops.cast(values, dtype='int32')\n",
    "        tp = tf.reduce_sum(values)\n",
    "        \n",
    "        # Verifica a quantidade de VERDADEIROS NEGATIVOS (TN)\n",
    "        values = tf.keras.ops.logical_and(tf.keras.ops.equal(y_true, False), tf.keras.ops.equal(y_pred, False))\n",
    "        values = tf.keras.ops.cast(values, dtype='int32')\n",
    "        tn = tf.reduce_sum(values)\n",
    "        \n",
    "        # Verifica a quantidade de FALSO POSITIVO (FP)\n",
    "        values = tf.keras.ops.logical_and(tf.keras.ops.equal(y_true, False), tf.keras.ops.equal(y_pred, True))\n",
    "        values = tf.keras.ops.cast(values, dtype='int32')\n",
    "        fp = tf.reduce_sum(values)\n",
    "\n",
    "        # Verifica a quantidade de FALSO NEGATIVO (FN)\n",
    "        values = tf.keras.ops.logical_and(tf.keras.ops.equal(y_true, True), tf.keras.ops.equal(y_pred, False))\n",
    "        values = tf.keras.ops.cast(values, dtype='int32')\n",
    "        fn = tf.reduce_sum(values) \n",
    "\n",
    "        # assign_add e assign em TensorFlow são usadas para atualizar os valores de tensores que foram definidos como variáveis de estado dentro de uma classe\n",
    "        # assign_add\n",
    "        # Função: Incrementa o valor da variável pelo valor especificado.\n",
    "        # Uso: É útil quando você deseja somar um valor ao valor atual da variável.\n",
    "        # Exemplo: self.true_positives.assign_add(tn)\n",
    "        # Isso adiciona o número de verdadeiros positivos encontrados na batch atual ao total acumulado de verdadeiros positivos.\n",
    "        # Use assign_add quando você precisa acumular valores ao longo do tempo, como ao acumular contagens de verdadeiros positivos, falsos positivos, etc., durante várias iterações ou batches de treinamento.\n",
    "        \n",
    "        self.true_positives.assign_add(tp)\n",
    "        self.true_negatives.assign_add(tn)\n",
    "        self.false_positives.assign_add(fp)\n",
    "        self.false_negatives.assign_add(fn)\n",
    "        \n",
    "    def result(self):\n",
    "\n",
    "        f1_1 = (2 * self.true_positives) / (2 * self.true_positives + self.false_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
    "        f1_0 = (2 * self.true_negatives) / (2 * self.true_negatives + self.false_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
    "\n",
    "        # F1-Score Macro\n",
    "        f = (f1_1 + f1_0) / 2 \n",
    "    \n",
    "        return f\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.true_positives.assign(0.0)\n",
    "        self.true_negatives.assign(0.0)\n",
    "        self.false_positives.assign(0.0)\n",
    "        self.false_negatives.assign(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Notas Adicionais**\n",
    "\n",
    "* **Compatibilidade**: A implementação da métrica deve garantir que todas as operações sejam compatíveis com as operações do TensorFlow.\n",
    "* **Estado**: Usar self.add_weight permite que a métrica mantenha estados persistentes durante o treinamento.\n",
    "* **Customização**: A abordagem usando a classe Metric facilita o reuso e a manutenção da métrica personalizada, especialmente em projetos complexos.\n",
    "* **Precisão Numérica**: A adição de tf.keras.backend.epsilon() evita divisões por zero.\n",
    "\n",
    "Essa implementação permite que você utilize a métrica F1-Score durante o treinamento e a avaliação do seu modelo de forma eficiente e integrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 306ms/step - f1_score: 0.4253 - loss: 0.6931 - val_f1_score: 0.3704 - val_loss: 0.6905\n",
      "Epoch 2/2\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 267ms/step - f1_score: 0.6239 - loss: 0.6804 - val_f1_score: 0.6767 - val_loss: 0.6073\n"
     ]
    }
   ],
   "source": [
    "# F1-Score \n",
    "metric = F1ScoreA()\n",
    "\n",
    "# Passando a métrica para o modelo\n",
    "model = build_model(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step\n",
      "F1-Score Macro Valid 0.68\n"
     ]
    }
   ],
   "source": [
    "metric = F1ScoreA()\n",
    "metric.update_state(y_valid, model.predict(X_valid))\n",
    "f1_macro_valid_a = tf.keras.ops.round(tf.convert_to_tensor(metric.result().numpy(), dtype=tf.float64), 2)\n",
    "\n",
    "print(f'F1-Score Macro Valid {f1_macro_valid_a}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Criando a Métrica F1-Score Customizada (com parâmetro) usando Keras/Tensorflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar limite de decisão para as probabilidades do modelo\n",
    "def to_labels(pos_probs, threshold):\n",
    "    return (pos_probs >= threshold).astype('int')\n",
    "\n",
    "class F1ScoreC(tf.keras.metrics.Metric):     \n",
    "    def __init__(self, Tipo='macro', Threshold=0.5, name='f1', **kwargs):\n",
    "        super(F1ScoreC, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.true_negatives = self.add_weight(name='tn', initializer='zeros')\n",
    "        self.false_positives = self.add_weight(name='fp', initializer='zeros')\n",
    "        self.false_negatives = self.add_weight(name='fn', initializer='zeros')\n",
    "        self.Tipo = Tipo\n",
    "        self.Threshold = Threshold\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        \n",
    "        # O y_true é um array de 1 Dimensão com valores inteiros.\n",
    "        # O y_pred é um array de 2 Dimensões com valores flutuantes, ou seja, com probabilidades das classes. \n",
    "        # Precisamos transformar o y_pred em inteiros e converter o array para 1D\n",
    "        # Iremos usar as funçãoes do Tensorflow\n",
    "        # 1) Arrendondar os valores do array\n",
    "        # 2) Transformar o array de 2D para 1D\n",
    "        # 3) Converter o tipo do array para int32\n",
    "        if self.Threshold != 0.5:\n",
    "            y_pred = to_labels(tf.reshape(y_pred, -1).numpy(), self.Threshold)\n",
    "            y_pred= tf.cast(tf.convert_to_tensor(y_pred), dtype='int32')\n",
    "        else:\n",
    "            y_pred = tf.cast(tf.reshape(tf.round(y_pred), -1), dtype='int32')\n",
    "\n",
    "        # O y_pred é um tensor do tipo int32.\n",
    "        # Vamos converter o y_true para tensor do tipo int32\n",
    "        y_true = tf.cast(tf.convert_to_tensor(y_true), dtype='int32')\n",
    "\n",
    "        # Transforma o array em valores booleanos [0, 1, 0, 1] -> [False, True, False, True]\n",
    "        y_true = tf.keras.ops.cast(y_true, \"bool\")\n",
    "        y_pred = tf.keras.ops.cast(y_pred, \"bool\")\n",
    "\n",
    "        # Verifica a quantidade de VERDADEIROS POSITIVOS (TP)\n",
    "        # Usaremos a função lógica \"and\" para verifica a quantidade de valores verdadeiros e falsos\n",
    "        #  A    and    B       S\n",
    "        # True       True  = True\n",
    "        # False      False = False\n",
    "        # True       True  = False\n",
    "        # True       True  = False\n",
    "        values = tf.keras.ops.logical_and(tf.keras.ops.equal(y_true, True), tf.keras.ops.equal(y_pred, True))\n",
    "        values = tf.keras.ops.cast(values, dtype='int32')\n",
    "        tp = tf.reduce_sum(values)\n",
    "        \n",
    "        # Verifica a quantidade de VERDADEIROS NEGATIVOS (TN)\n",
    "        values = tf.keras.ops.logical_and(tf.keras.ops.equal(y_true, False), tf.keras.ops.equal(y_pred, False))\n",
    "        values = tf.keras.ops.cast(values, dtype='int32')\n",
    "        tn = tf.reduce_sum(values)\n",
    "        \n",
    "        # Verifica a quantidade de FALSO POSITIVO (FP)\n",
    "        values = tf.keras.ops.logical_and(tf.keras.ops.equal(y_true, False), tf.keras.ops.equal(y_pred, True))\n",
    "        values = tf.keras.ops.cast(values, dtype='int32')\n",
    "        fp = tf.reduce_sum(values)\n",
    "\n",
    "        # Verifica a quantidade de FALSO NEGATIVO (FN)\n",
    "        values = tf.keras.ops.logical_and(tf.keras.ops.equal(y_true, True), tf.keras.ops.equal(y_pred, False))\n",
    "        values = tf.keras.ops.cast(values, dtype='int32')\n",
    "        fn = tf.reduce_sum(values) \n",
    "\n",
    "        # assign_add e assign em TensorFlow são usadas para atualizar os valores de tensores que foram definidos como variáveis de estado dentro de uma classe\n",
    "        # assign_add\n",
    "        # Função: Incrementa o valor da variável pelo valor especificado.\n",
    "        # Uso: É útil quando você deseja somar um valor ao valor atual da variável.\n",
    "        # Exemplo: self.true_positives.assign_add(tn)\n",
    "        # Isso adiciona o número de verdadeiros positivos encontrados na batch atual ao total acumulado de verdadeiros positivos.\n",
    "        # Use assign_add quando você precisa acumular valores ao longo do tempo, como ao acumular contagens de verdadeiros positivos, falsos positivos, etc., durante várias iterações ou batches de treinamento.\n",
    "        \n",
    "        self.true_positives.assign_add(tp)\n",
    "        self.true_negatives.assign_add(tn)\n",
    "        self.false_positives.assign_add(fp)\n",
    "        self.false_negatives.assign_add(fn)\n",
    "        \n",
    "    def result(self):\n",
    "        f = 0\n",
    "\n",
    "        f1_1 = (2 * self.true_positives) / (2 * self.true_positives + self.false_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
    "        f1_0 = (2 * self.true_negatives) / (2 * self.true_negatives + self.false_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
    "\n",
    "        if self.Tipo == 'macro':\n",
    "            f = (f1_1 + f1_0) / 2\n",
    "        elif self.Tipo == 'micro':\n",
    "            f = (self.true_positives + self.true_negatives) / (self.true_positives + self.false_positives + self.false_negatives + self.true_negatives + tf.keras.backend.epsilon())\n",
    "        elif self.Tipo == 'weighted':\n",
    "            f = (((self.true_positives + self.false_negatives) * f1_1) + ((self.false_positives + self.true_negatives) * f1_0)) / ((self.true_positives + self.false_negatives) + (self.false_positives + self.true_negatives) + tf.keras.backend.epsilon())\n",
    "    \n",
    "        return f\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.true_positives.assign(0.0)\n",
    "        self.true_negatives.assign(0.0)\n",
    "        self.false_positives.assign(0.0)\n",
    "        self.false_negatives.assign(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Passando o Tipo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 307ms/step - f1: 0.4874 - loss: 0.6928 - val_f1: 0.4306 - val_loss: 0.6840\n",
      "Epoch 2/2\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 339ms/step - f1: 0.6341 - loss: 0.6620 - val_f1: 0.7282 - val_loss: 0.5753\n"
     ]
    }
   ],
   "source": [
    "# F1-Score\n",
    "metric = F1ScoreC('weighted')\n",
    "\n",
    "# Passando a métrica para o modelo\n",
    "model = build_model(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step\n",
      "F1-Score Macro Valid 0.73 F1-Score Micro Valid 0.73 F1-Score Weighted Valid 0.73\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "metric = F1ScoreC('weighted')\n",
    "metric.update_state(y_valid, y_pred)\n",
    "f1_weighted_valid_c = tf.keras.ops.round(tf.convert_to_tensor(metric.result().numpy(), dtype=tf.float64), 2)\n",
    "\n",
    "metric = F1ScoreC('macro')\n",
    "metric.update_state(y_valid, y_pred)\n",
    "f1_macro_valid_c = tf.keras.ops.round(tf.convert_to_tensor(metric.result().numpy(), dtype=tf.float64), 2)\n",
    "\n",
    "metric = F1ScoreC('micro')\n",
    "metric.update_state(y_valid, y_pred)\n",
    "f1_micro_valid_c = tf.keras.ops.round(tf.convert_to_tensor(metric.result().numpy(), dtype=tf.float64), 2)\n",
    "\n",
    "\n",
    "print(f'F1-Score Macro Valid {f1_macro_valid_c} F1-Score Micro Valid {f1_micro_valid_c} F1-Score Weighted Valid {f1_weighted_valid_c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.61      0.69      4947\n",
      "           1       0.69      0.85      0.76      5053\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.75      0.73      0.73     10000\n",
      "weighted avg       0.74      0.73      0.73     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, np.reshape(np.round(y_pred), -1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Passando o Tipo e o Threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 332ms/step - f1: 0.3314 - loss: 0.6928 - val_f1: 0.3392 - val_loss: 0.6864\n",
      "Epoch 2/2\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 352ms/step - f1: 0.3857 - loss: 0.6669 - val_f1: 0.6498 - val_loss: 0.5831\n"
     ]
    }
   ],
   "source": [
    "# F1-Score\n",
    "metric = F1ScoreC('weighted', 0.356)\n",
    "\n",
    "# Passando a métrica para o modelo\n",
    "model = build_model(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step\n",
      "F1-Score Macro Valid 0.65 F1-Score Micro Valid 0.67 F1-Score Weighted Valid 0.65\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "metric = F1ScoreC('weighted', 0.356)\n",
    "metric.update_state(y_valid, y_pred)\n",
    "f1_weighted_valid_c = tf.keras.ops.round(tf.convert_to_tensor(metric.result().numpy(), dtype=tf.float64), 2)\n",
    "\n",
    "metric = F1ScoreC('macro', 0.356)\n",
    "metric.update_state(y_valid, y_pred)\n",
    "f1_macro_valid_c = tf.keras.ops.round(tf.convert_to_tensor(metric.result().numpy(), dtype=tf.float64), 2)\n",
    "\n",
    "metric = F1ScoreC('micro', 0.356)\n",
    "metric.update_state(y_valid, y_pred)\n",
    "f1_micro_valid_c = tf.keras.ops.round(tf.convert_to_tensor(metric.result().numpy(), dtype=tf.float64), 2)\n",
    "\n",
    "\n",
    "print(f'F1-Score Macro Valid {f1_macro_valid_c} F1-Score Micro Valid {f1_micro_valid_c} F1-Score Weighted Valid {f1_weighted_valid_c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ = tf.cast(tf.convert_to_tensor(to_labels(tf.reshape(y_pred, -1).numpy(), 0.356)), dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.44      0.57      4947\n",
      "           1       0.62      0.89      0.73      5053\n",
      "\n",
      "    accuracy                           0.67     10000\n",
      "   macro avg       0.71      0.67      0.65     10000\n",
      "weighted avg       0.71      0.67      0.65     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, y_pred_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Criando a Métrica F1-Score Customizada (com parâmetro) usando Keras/Tensorflow e Numpy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar limite de decisão para as probabilidades do modelo\n",
    "def to_labels(pos_probs, threshold):\n",
    "    return (pos_probs >= threshold).astype('int')\n",
    "\n",
    "class F1ScoreD(tf.keras.metrics.Metric):     \n",
    "    def __init__(self, Tipo='macro', Threshold=0.5, name='f1', **kwargs):\n",
    "        super(F1ScoreD, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.true_negatives = self.add_weight(name='tn', initializer='zeros')\n",
    "        self.false_positives = self.add_weight(name='fp', initializer='zeros')\n",
    "        self.false_negatives = self.add_weight(name='fn', initializer='zeros')\n",
    "        self.Tipo = Tipo\n",
    "        self.Threshold = Threshold\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        \n",
    "        # O y_true é um array de 1 Dimensão com valores inteiros.\n",
    "        # O y_pred é um array de 2 Dimensões com valores flutuantes, ou seja, com probabilidades das classes. \n",
    "        # Precisamos transformar o y_pred em inteiros e converter o array para 1D\n",
    "        # Iremos usar as funçãoes do Tensorflow\n",
    "        # 1) Arrendondar os valores do array\n",
    "        # 2) Transformar o array de 2D para 1D\n",
    "        # 3) Converter o tipo do array para int32\n",
    "        if self.Threshold != 0.5:\n",
    "            y_pred = to_labels(tf.reshape(y_pred, -1).numpy(), self.Threshold)\n",
    "        else:\n",
    "            y_pred = np.array(np.reshape(np.round(y_pred), -1), np.int32)\n",
    "\n",
    "\n",
    "        # Transforma o array em valores booleanos [0, 1, 0, 1] -> [False, True, False, True]\n",
    "        y_true = np.bool_(y_true)\n",
    "        y_pred = np.bool_(y_pred)\n",
    "\n",
    "        # Verifica a quantidade de VERDADEIROS POSITIVOS (TP)\n",
    "        # Usaremos a função lógica \"and\" para verifica a quantidade de valores verdadeiros e falsos\n",
    "        #  A    and    B       S\n",
    "        # True       True  = True\n",
    "        # False      False = False\n",
    "        # True       True  = False\n",
    "        # True       True  = False\n",
    "        values = np.logical_and(np.equal(y_true, True), np.equal(y_pred, True))\n",
    "        # Transforma o array/list de booleano para inteiro: [False,  True, False,  True] --> [0,1,0,1]\n",
    "        values = values.astype(int)  \n",
    "        # Faz a soma do array/list\n",
    "        tp = np.sum(values)\n",
    "        \n",
    "        # Verifica a quantidade de VERDADEIROS NEGATIVOS (TN)\n",
    "        values = np.logical_and(np.equal(y_true, False), np.equal(y_pred, False))\n",
    "        # Transforma o array/list de booleano para inteiro: [False,  True, False,  True] --> [0,1,0,1]\n",
    "        values = values.astype(int)  \n",
    "        # Faz a soma do array/list\n",
    "        tn = np.sum(values)\n",
    "        \n",
    "        # Verifica a quantidade de FALSO POSITIVO (FP)\n",
    "        values = np.logical_and(np.equal(y_true, False), np.equal(y_pred, True))\n",
    "        # Transforma o array/list de booleano para inteiro: [False,  True, False,  True] --> [0,1,0,1]\n",
    "        values = values.astype(int)  \n",
    "        # Faz a soma do array/list\n",
    "        fp = np.sum(values)\n",
    "\n",
    "        # Verifica a quantidade de FALSO NEGATIVO (FN)\n",
    "        values = np.logical_and(np.equal(y_true, True), np.equal(y_pred, False))\n",
    "        # Transforma o array/list de booleano para inteiro: [False,  True, False,  True] --> [0,1,0,1]\n",
    "        values = values.astype(int)  \n",
    "        # Faz a soma do array/list\n",
    "        fn = np.sum(values)\n",
    "\n",
    "        # assign_add e assign em TensorFlow são usadas para atualizar os valores de tensores que foram definidos como variáveis de estado dentro de uma classe\n",
    "        # assign_add\n",
    "        # Função: Incrementa o valor da variável pelo valor especificado.\n",
    "        # Uso: É útil quando você deseja somar um valor ao valor atual da variável.\n",
    "        # Exemplo: self.true_positives.assign_add(tn)\n",
    "        # Isso adiciona o número de verdadeiros positivos encontrados na batch atual ao total acumulado de verdadeiros positivos.\n",
    "        # Use assign_add quando você precisa acumular valores ao longo do tempo, como ao acumular contagens de verdadeiros positivos, falsos positivos, etc., durante várias iterações ou batches de treinamento.\n",
    "        \n",
    "        self.true_positives.assign_add(tp)\n",
    "        self.true_negatives.assign_add(tn)\n",
    "        self.false_positives.assign_add(fp)\n",
    "        self.false_negatives.assign_add(fn)\n",
    "        \n",
    "    def result(self):\n",
    "        f = 0\n",
    "\n",
    "        f1_1 = (2 * self.true_positives) / (2 * self.true_positives + self.false_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
    "        f1_0 = (2 * self.true_negatives) / (2 * self.true_negatives + self.false_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
    "\n",
    "        if self.Tipo == 'macro':\n",
    "            f = (f1_1 + f1_0) / 2 \n",
    "        elif self.Tipo == 'micro':\n",
    "            f = (self.true_positives + self.true_negatives) / (self.true_positives + self.false_positives + self.false_negatives + self.true_negatives + tf.keras.backend.epsilon())\n",
    "        elif self.Tipo == 'weighted':\n",
    "            f = (((self.true_positives + self.false_negatives) * f1_1) + ((self.false_positives + self.true_negatives) * f1_0)) / ((self.true_positives + self.false_negatives) + (self.false_positives + self.true_negatives) + tf.keras.backend.epsilon())\n",
    "    \n",
    "        return f\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.true_positives.assign(0.0)\n",
    "        self.true_negatives.assign(0.0)\n",
    "        self.false_positives.assign(0.0)\n",
    "        self.false_negatives.assign(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 331ms/step - f1: 0.3227 - loss: 0.6920 - val_f1: 0.3392 - val_loss: 0.6789\n",
      "Epoch 2/2\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 333ms/step - f1: 0.4358 - loss: 0.6593 - val_f1: 0.6299 - val_loss: 0.5776\n"
     ]
    }
   ],
   "source": [
    "# F1-Score\n",
    "metric = F1ScoreD('weighted', 0.356)\n",
    "\n",
    "# Passando a métrica para o modelo\n",
    "model = build_model(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step\n",
      "F1-Score Macro Valid 0.63 F1-Score Micro Valid 0.65 F1-Score Weighted Valid 0.63\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "metric = F1ScoreD('weighted', 0.356)\n",
    "metric.update_state(y_valid, y_pred)\n",
    "f1_weighted_valid_c = tf.keras.ops.round(tf.convert_to_tensor(metric.result().numpy(), dtype=tf.float64), 2)\n",
    "\n",
    "metric = F1ScoreD('macro', 0.356)\n",
    "metric.update_state(y_valid, y_pred)\n",
    "f1_macro_valid_c = tf.keras.ops.round(tf.convert_to_tensor(metric.result().numpy(), dtype=tf.float64), 2)\n",
    "\n",
    "metric = F1ScoreD('micro', 0.356)\n",
    "metric.update_state(y_valid, y_pred)\n",
    "f1_micro_valid_c = tf.keras.ops.round(tf.convert_to_tensor(metric.result().numpy(), dtype=tf.float64), 2)\n",
    "\n",
    "\n",
    "print(f'F1-Score Macro Valid {f1_macro_valid_c} F1-Score Micro Valid {f1_micro_valid_c} F1-Score Weighted Valid {f1_weighted_valid_c}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Métrica F1-Score Customizada (com parâmetros) usando Keras/TensorFlow e Scikit-Learn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def to_labels(pos_probs, threshold):\n",
    "    return (pos_probs >= threshold).astype('int')\n",
    "\n",
    "\n",
    "class F1ScoreE(tf.keras.metrics.Metric):\n",
    "    def __init__(self, Tipo='macro', Threshold=0.5, name='f1', **kwargs):\n",
    "        super(F1ScoreE, self).__init__(name=name, **kwargs)\n",
    "        self.f1 = self.add_weight(name='f1_', initializer='zeros')\n",
    "        self.Tipo = Tipo\n",
    "        self.Threshold = Threshold\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        if self.Threshold != 0.5:\n",
    "            y_pred = to_labels(tf.reshape(y_pred, -1).numpy(), self.Threshold)\n",
    "        else:\n",
    "            y_pred = np.array(np.reshape(np.round(y_pred), -1), np.int32)\n",
    "\n",
    "        f1 = f1_score(y_true, y_pred, average=self.Tipo)\n",
    "\n",
    "        self.f1.assign(f1)     \n",
    "\n",
    "    def result(self):\n",
    "        return self.f1\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.f1.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 294ms/step - f1: 0.3309 - loss: 0.6928 - val_f1: 0.3665 - val_loss: 0.6884\n",
      "Epoch 2/2\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 292ms/step - f1: 0.4568 - loss: 0.6722 - val_f1: 0.6313 - val_loss: 0.5919\n"
     ]
    }
   ],
   "source": [
    "# F1-Score\n",
    "metric = F1ScoreE('weighted', 0.356)\n",
    "\n",
    "# Passando a métrica para o modelo\n",
    "model = build_model(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step\n",
      "F1-Score Macro Valid 0.62 F1-Score Micro Valid 0.64 F1-Score Weighted Valid 0.62\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "metric = F1ScoreE('weighted', 0.356)\n",
    "metric.update_state(y_valid, y_pred)\n",
    "f1_weighted_valid_c = tf.keras.ops.round(tf.convert_to_tensor(metric.result().numpy(), dtype=tf.float64), 2)\n",
    "\n",
    "metric = F1ScoreE('macro', 0.356)\n",
    "metric.update_state(y_valid, y_pred)\n",
    "f1_macro_valid_c = tf.keras.ops.round(tf.convert_to_tensor(metric.result().numpy(), dtype=tf.float64), 2)\n",
    "\n",
    "metric = F1ScoreE('micro', 0.356)\n",
    "metric.update_state(y_valid, y_pred)\n",
    "f1_micro_valid_c = tf.keras.ops.round(tf.convert_to_tensor(metric.result().numpy(), dtype=tf.float64), 2)\n",
    "\n",
    "\n",
    "print(f'F1-Score Macro Valid {f1_macro_valid_c} F1-Score Micro Valid {f1_micro_valid_c} F1-Score Weighted Valid {f1_weighted_valid_c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.38      0.51      4947\n",
      "           1       0.60      0.90      0.72      5053\n",
      "\n",
      "    accuracy                           0.64     10000\n",
      "   macro avg       0.69      0.64      0.62     10000\n",
      "weighted avg       0.69      0.64      0.62     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_ = tf.cast(tf.convert_to_tensor(to_labels(tf.reshape(y_pred, -1).numpy(), 0.356)), dtype='int32')\n",
    "print(classification_report(y_valid, y_pred_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Métrica Balanced Accuracy Customizada com Keras/Tensorflow**\n",
    "\n",
    "A balanced_accuracy_score função calcula a precisão balanceada, o que evita estimativas de desempenho inflacionadas em conjuntos de dados desequilibrados. \n",
    "\n",
    "No caso binário, a precisão balanceada é igual à média aritmética de sensibilidade (taxa verdadeira positiva) e especificidade (taxa verdadeira negativa), ou a área sob a curva ROC com previsões binárias em vez de pontuações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar limite de decisão para as probabilidades do modelo\n",
    "def to_labels(pos_probs, threshold):\n",
    "    return (pos_probs >= threshold).astype('int')\n",
    "\n",
    "class CustomBalancedAccuracyA(tf.keras.metrics.Metric):\n",
    "    def __init__(self, Threshold=0.5, name='CustomBalancedAccuracy', **kwargs):\n",
    "        super(CustomBalancedAccuracyA, self).__init__(name=name, **kwargs)\n",
    "        self.Threshold = Threshold\n",
    "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.false_positives = self.add_weight(name='fp', initializer='zeros')\n",
    "        self.true_negatives = self.add_weight(name='tn', initializer='zeros')\n",
    "        self.false_negatives = self.add_weight(name='fn', initializer='zeros')\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # O y_true é um array de 1 Dimensão com valores inteiros.\n",
    "        # O y_pred é um array de 2 Dimensões com valores flutuantes, ou seja, com probabilidades das classes. \n",
    "        # Precisamos transformar o y_pred em inteiros e converter o array para 1D\n",
    "        # Iremos usar as funçãoes do Tensorflow\n",
    "        # 1) Arrendondar os valores do array\n",
    "        # 2) Transformar o array de 2D para 1D\n",
    "        # 3) Converter o tipo do array para int32\n",
    "        if self.Threshold != 0.5:\n",
    "            y_pred = to_labels(tf.reshape(y_pred, -1).numpy(), self.Threshold)\n",
    "            y_pred= tf.cast(tf.convert_to_tensor(y_pred), dtype='int32')\n",
    "        else:\n",
    "            y_pred = tf.cast(tf.reshape(tf.round(y_pred), -1), dtype='int32')\n",
    "\n",
    "        # O y_pred é um tensor do tipo int32.\n",
    "        # Vamos converter o y_true para tensor do tipo int32\n",
    "        y_true = tf.cast(tf.convert_to_tensor(y_true), dtype='int32')\n",
    "\n",
    "        # Transforma o array em valores booleanos [0, 1, 0, 1] -> [False, True, False, True]\n",
    "        y_true = tf.keras.ops.cast(y_true, \"bool\")\n",
    "        y_pred = tf.keras.ops.cast(y_pred, \"bool\")\n",
    "\n",
    "        # Verifica a quantidade de VERDADEIROS POSITIVOS (TP)\n",
    "        # Usaremos a função lógica \"and\" para verifica a quantidade de valores verdadeiros e falsos\n",
    "        #  A    and    B       S\n",
    "        # True       True  = True\n",
    "        # False      False = False\n",
    "        # True       True  = False\n",
    "        # True       True  = False\n",
    "        values = tf.keras.ops.logical_and(tf.keras.ops.equal(y_true, True), tf.keras.ops.equal(y_pred, True))\n",
    "        values = tf.keras.ops.cast(values, dtype='int32')\n",
    "        tp = tf.reduce_sum(values)\n",
    "        \n",
    "        # Verifica a quantidade de VERDADEIROS NEGATIVOS (TN)\n",
    "        values = tf.keras.ops.logical_and(tf.keras.ops.equal(y_true, False), tf.keras.ops.equal(y_pred, False))\n",
    "        values = tf.keras.ops.cast(values, dtype='int32')\n",
    "        tn = tf.reduce_sum(values)\n",
    "        \n",
    "        # Verifica a quantidade de FALSO POSITIVO (FP)\n",
    "        values = tf.keras.ops.logical_and(tf.keras.ops.equal(y_true, False), tf.keras.ops.equal(y_pred, True))\n",
    "        values = tf.keras.ops.cast(values, dtype='int32')\n",
    "        fp = tf.reduce_sum(values)\n",
    "\n",
    "        # Verifica a quantidade de FALSO NEGATIVO (FN)\n",
    "        values = tf.keras.ops.logical_and(tf.keras.ops.equal(y_true, True), tf.keras.ops.equal(y_pred, False))\n",
    "        values = tf.keras.ops.cast(values, dtype='int32')\n",
    "        fn = tf.reduce_sum(values) \n",
    "\n",
    "        # assign_add e assign em TensorFlow são usadas para atualizar os valores de tensores que foram definidos como variáveis de estado dentro de uma classe\n",
    "        # assign_add\n",
    "        # Função: Incrementa o valor da variável pelo valor especificado.\n",
    "        # Uso: É útil quando você deseja somar um valor ao valor atual da variável.\n",
    "        # Exemplo: self.true_positives.assign_add(tn)\n",
    "        # Isso adiciona o número de verdadeiros positivos encontrados na batch atual ao total acumulado de verdadeiros positivos.\n",
    "        # Use assign_add quando você precisa acumular valores ao longo do tempo, como ao acumular contagens de verdadeiros positivos, falsos positivos, etc., durante várias iterações ou batches de treinamento.\n",
    "      \n",
    "        self.true_positives.assign_add(tp)\n",
    "        self.false_positives.assign_add(fp)\n",
    "        self.true_negatives.assign_add(tn)\n",
    "        self.false_negatives.assign_add(fn)\n",
    "    \n",
    "    def result(self):\n",
    "        recall = self.true_positives / (self.true_positives + self.false_negatives + tf.keras.backend.epsilon())\n",
    "        specificity = self.true_negatives / (self.true_negatives + self.false_positives + tf.keras.backend.epsilon())\n",
    "        balanced_accuracy = (recall + specificity) / 2\n",
    "        return balanced_accuracy\n",
    "    \n",
    "    def reset_states(self):\n",
    "        self.true_positives.assign(0.0)\n",
    "        self.false_positives.assign(0.0)\n",
    "        self.true_negatives.assign(0.0)\n",
    "        self.false_negatives.assign(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 302ms/step - CustomBalancedAccuracy: 0.5000 - loss: 0.6927 - val_CustomBalancedAccuracy: 0.5000 - val_loss: 0.6896\n",
      "Epoch 2/2\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 315ms/step - CustomBalancedAccuracy: 0.5050 - loss: 0.6778 - val_CustomBalancedAccuracy: 0.6207 - val_loss: 0.5988\n"
     ]
    }
   ],
   "source": [
    "# BalancedAccuracyA\n",
    "metric =  CustomBalancedAccuracyA(0.356)\n",
    "\n",
    "# Passando a métrica para o modelo\n",
    "model = build_model(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step\n",
      "CustomBalancedAccuracyA Valid 0.62 0.62\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "metric = CustomBalancedAccuracyA(0.356)\n",
    "metric.update_state(y_valid, y_pred)\n",
    "ba_valid_a = tf.keras.ops.round(tf.convert_to_tensor(metric.result().numpy(), dtype=tf.float64), 2)\n",
    "\n",
    "score = np.round(balanced_accuracy_score(y_valid, to_labels(np.reshape(y_pred, -1), 0.356)), 2)\n",
    "\n",
    "print(f'CustomBalancedAccuracyA Valid {ba_valid_a} {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Métrica Balanced Accuracy Customizada com Keras/Tensorflow e Scikit-Learn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Aplicar limite de decisão para as probabilidades do modelo\n",
    "def to_labels(pos_probs, threshold):\n",
    "    return (pos_probs >= threshold).astype('int')\n",
    "\n",
    "\n",
    "class CustomBalancedAccuracyB(tf.keras.metrics.Metric):\n",
    "    def __init__(self, Threshold=0.5, name='CustomBalancedAccuracy', **kwargs):\n",
    "        super(CustomBalancedAccuracyB, self).__init__(name=name, **kwargs)\n",
    "        self.balanced_acc = self.add_weight(name='Acc', initializer='zeros')\n",
    "        self.Threshold = Threshold\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        if self.Threshold != 0.5:\n",
    "            y_pred = to_labels(tf.reshape(y_pred, -1).numpy(), self.Threshold)\n",
    "        else:\n",
    "            y_pred = np.array(np.reshape(np.round(y_pred), -1), np.int32)\n",
    "\n",
    "        bc = balanced_accuracy_score(y_true, y_pred) \n",
    "\n",
    "        self.balanced_acc.assign(bc)     \n",
    "\n",
    "    def result(self):\n",
    "        return self.balanced_acc\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.balanced_acc.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 267ms/step - CustomBalancedAccuracy: 0.5000 - loss: 0.6925 - val_CustomBalancedAccuracy: 0.5000 - val_loss: 0.6855\n",
      "Epoch 2/2\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 270ms/step - CustomBalancedAccuracy: 0.5500 - loss: 0.6642 - val_CustomBalancedAccuracy: 0.6632 - val_loss: 0.5720\n"
     ]
    }
   ],
   "source": [
    "# BalancedAccuracy\n",
    "metric = CustomBalancedAccuracyB(0.356)\n",
    "\n",
    "# Passando a métrica para o modelo\n",
    "model = build_model(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step\n",
      "CustomBalancedAccuracyA Valid 0.65\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "metric = CustomBalancedAccuracyB(0.356)\n",
    "metric.update_state(y_valid, y_pred)\n",
    "ba_valid_b = tf.keras.ops.round(tf.convert_to_tensor(metric.result().numpy(), dtype=tf.float64), 2)\n",
    "\n",
    "print(f'CustomBalancedAccuracyA Valid {ba_valid_b}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
