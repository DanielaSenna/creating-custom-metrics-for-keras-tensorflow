{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Criando Métricas Personalizadas Para Keras/Tensorflow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode implementar sua própria métrica e usá-la como objetivo e na busca de hiperparâmetros.\n",
    "\n",
    "\n",
    "Nesse notebook, iremos implementar com o Keras/Tensorflow duas métricas do Scikit-Learn para avaliar o desempenho de uma Rede Neural Convolucional (CNN):\n",
    "* F1-Score\n",
    "* BalancedAccuracy\n",
    "\n",
    "[Custom metric as the objective](https://keras.io/guides/keras_tuner/getting_started/#tune-model-training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Importando as Bibliotecas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Classificação de Texto com Avaliações de Filmes**\n",
    "\n",
    "\n",
    "Este notebook classifica avaliações de filmes como positiva ou negativa usando o texto da avaliação. Isto é um exemplo de classificação binária —ou duas-classes—, um importante e bastante aplicado tipo de problema de aprendizado de máquina.\n",
    "\n",
    "Usaremos a base de dados IMDB que contém avaliaçòes de mais de 50000 filmes da base de dados Internet Movie Database. \n",
    "\n",
    "A base é dividida em 25000 avaliações para treinamento e 25000 para teste. Os conjuntos de **treinamentos e testes são balanceados**, ou seja, eles possuem a mesma quantidade de avaliações positivas e negativas.\n",
    "\n",
    "O notebook utiliza tf.keras, uma API alto-nível para construir e treinar modelos com TensorFlow\n",
    "\n",
    "[Text Classification Keras/Tensorflow](https://www.tensorflow.org/tutorials/keras/text_classification?hl=pt-br)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baixe a base de dados IMDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A base de dados vem empacotada com TensorFlow. \n",
    "# Ela já vem pré-processada de forma que as avaliações (sequências de palavras) foram convertidas em sequências de inteiros, onde cada inteiro representa uma palavra específica no dicionário.\n",
    "# O argumento num_words=10000 mantém as 10000 palavras mais frequentes no conjunto de treinamento. As palavras mais raras são descartadas para preservar o tamanho dos dados de forma maleável.\n",
    "\n",
    "imdb = tf.keras.datasets.imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conjunto de Treinamento e Teste**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training entries: 25000, labels: 25000\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "\n",
    "print(\"Training entries: {}, labels: {}\".format(len(train_data), len(train_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore os dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "# Vamos parar um momento para entender o formato dos dados. \n",
    "# O conjunto de dados vem pré-processado: cada exemplo é um array de inteiros representando as palavras da avaliação do filme. \n",
    "# Cada label é um inteiro com valor ou de 0 ou 1, onde 0 é uma avaliação negativa e 1 é uma avaliação positiva.\n",
    "# O texto das avaliações foi convertido para inteiros, onde cada inteiro representa uma palavra específica no dicionário. Isso é como se parece a primeira revisão:\n",
    "\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 189)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As avaliações dos filmes têm tamanhos diferentes. \n",
    "# O código abaixo mostra o número de palavras da primeira e segunda avaliação. \n",
    "# Sabendo que o número de entradas da rede neural tem que ser o mesmo também, temos que resolver isto mais tarde.\n",
    "\n",
    "len(train_data[0]), len(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "       ...,\n",
       "       list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 7750, 5, 4241, 18, 4, 8497, 2, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 2, 4, 3586, 2]),\n",
       "       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 8778, 2, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare os Dados**\n",
    "\n",
    "As avaliações —os arrays de inteiros— devem ser convertidas em tensores (tensors) antes de alimentar a rede neural. Essa conversão pode ser feita de duas formas:\n",
    "\n",
    "* Converter os arrays em vetores de 0s e 1s indicando a ocorrência da palavra, similar com one-hot encoding. Por exemplo, a sequência [3, 5] se tornaria um vetor de 10000 dimensões, onde todos seriam 0s, tirando 3 e 5, que são 1s. Depois, faça disso a primeira camada da nossa rede neural — a Dense layer — que pode trabalhar com dados em ponto flutuante. Essa abordagem é intensa em relação a memória, logo requer uma matriz de tamanho num_words * num_reviews.\n",
    "\n",
    "* Alternativamente, podemos preencher o array para que todos tenho o mesmo comprimento, e depois criar um tensor inteiro de formato max_length * num_reviews. Podemos usar uma camada embedding capaz de lidar com o formato como a primeira camada da nossa rede.\n",
    "\n",
    "Nesse notebook, usaremos a segunda abordagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Já que as avaliações dos filmes devem ter o mesmo tamanho, usaremos a função pad_sequences para padronizar os tamanhos:\n",
    "\n",
    "# Um dicionário mapeando palavras em índices inteiros\n",
    "word_index = imdb.get_word_index()\n",
    "word_index[\"<PAD>\"] = 0\n",
    "\n",
    "train_data = tf.keras.preprocessing.sequence.pad_sequences(train_data,\n",
    "                                                        value=word_index[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=256)\n",
    "\n",
    "test_data = tf.keras.preprocessing.sequence.pad_sequences(test_data,\n",
    "                                                       value=word_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,   14,   22, ...,    0,    0,    0],\n",
       "       [   1,  194, 1153, ...,    0,    0,    0],\n",
       "       [   1,   14,   47, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   1,   11,    6, ...,    0,    0,    0],\n",
       "       [   1, 1446, 7079, ...,    0,    0,    0],\n",
       "       [   1,   17,    6, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agora, vamos olhar o tamanho dos exemplos:\n",
    "\n",
    "\n",
    "len(train_data[0]), len(train_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criando um Conjunto de Validação**\n",
    "\n",
    "Quando treinamos. queremos checar a acurácia do modelo com os dados que ele nunca viu. \n",
    "\n",
    "Crie uma conjunto de validação tirando 10000 exemplos do conjunto de treinamento original. \n",
    "\n",
    "(Por que não usar o de teste agora? Nosso objetivo é desenvolver e melhorar (tunar) nosso modelo usando somente os dados de treinamento, depois usaremos o teste uma única vez para avaliar a previsão)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = train_data[:10000]\n",
    "X_train = train_data[10000:]\n",
    "\n",
    "y_valid = train_labels[:10000]\n",
    "y_train = train_labels[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criando a Métrica F1-Score Customizada (sem parâmetro) usando Keras**\n",
    "\n",
    "[f1-score-guide](https://www.v7labs.com/blog/f1-score-guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O Tensorflow 2 possui uma opção de configuração para executar funções \"avidamente\", o que permitirá obter valores do Tensor por meio do método .numpy(). \n",
    "# Para habilitar a execução antecipada, use o seguinte comando: tf.config.run_functions_eagerly(True)\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "tf.data.experimental.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomF1ScoreA(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1-score-macro', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.f1_macro = self.add_variable(shape=(), initializer='zeros', name='f1-macro')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        \n",
    "        y_pred = tf.cast(tf.reshape(tf.round(y_pred), -1), 'int32')\n",
    "        #y_true = tf.cast(tf.reshape(y_true, shape=(-1, 1)), 'int32')\n",
    "\n",
    "        y_true = tf.keras.ops.cast(y_true, \"bool\")\n",
    "        y_pred = tf.keras.ops.cast(y_pred, \"bool\")\n",
    "\n",
    "        # Verifica a quantidade de VERDADEIROS POSITIVOS (TP)\n",
    "        values = tf.keras.ops.logical_and(tf.keras.ops.equal(y_true, True), tf.keras.ops.equal(y_pred, True))\n",
    "        values = tf.keras.ops.cast(values, dtype='int32')\n",
    "        tp = tf.keras.ops.sum(values).numpy()\n",
    "        \n",
    "        # Verifica a quantidade de VERDADEIROS NEGATIVOS (TN)\n",
    "        values = tf.keras.ops.logical_and(tf.keras.ops.equal(y_true, False), tf.keras.ops.equal(y_pred, False))\n",
    "        values = tf.keras.ops.cast(values, dtype='int32')\n",
    "        tn = tf.keras.ops.sum(values).numpy()\n",
    "        \n",
    "        # Verifica a quantidade de FALSO POSITIVO (FP)\n",
    "        values = tf.keras.ops.logical_and(tf.keras.ops.equal(y_true, False), tf.keras.ops.equal(y_pred, True))\n",
    "        values = tf.keras.ops.cast(values, dtype='int32')\n",
    "        fp = tf.keras.ops.sum(values).numpy()\n",
    "\n",
    "        # Verifica a quantidade de FALSO NEGATIVO (FN)\n",
    "        values = tf.keras.ops.logical_and(tf.keras.ops.equal(y_true, True), tf.keras.ops.equal(y_pred, False))\n",
    "        values = tf.keras.ops.cast(values, dtype='int32')\n",
    "        fn = tf.keras.ops.sum(values).numpy()\n",
    "\n",
    "        f1_1 = (2 * tp) / (2 * tp + fp + fn)\n",
    "        f1_0 = (2 * tn) / (2 * tn + fp + fn)\n",
    "        f1 = (f1_1 + f1_0) / 2\n",
    "\n",
    "        self.f1_macro.assign(f1)\n",
    "\n",
    "    def result(self):\n",
    "        return self.f1_macro\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.f1_macro.assign(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criando a Métrica F1-Score Customizada (com parâmetro) usando Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomF1ScoreB(tf.keras.metrics.Metric): \n",
    "    def __init__(self, name='f1', Tipo='macro'):\n",
    "        super(CustomF1ScoreB, self).__init__()\n",
    "        self.f1 = self.add_weight(name=name, initializer='zeros')\n",
    "        self.Tipo = Tipo\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "    \n",
    "        y_pred = tf.cast(tf.reshape(tf.round(y_pred), -1), 'int32')\n",
    "        #y_true = tf.cast(tf.reshape(y_true, shape=(-1, 1)), 'int32')\n",
    "\n",
    "        y_true = tf.keras.ops.cast(y_true, \"bool\")\n",
    "        y_pred = tf.keras.ops.cast(y_pred, \"bool\")\n",
    "\n",
    "        # Verifica a quantidade de VERDADEIROS POSITIVOS (TP)\n",
    "        values = tf.keras.ops.logical_and(tf.keras.ops.equal(y_true, True), tf.keras.ops.equal(y_pred, True))\n",
    "        values = tf.keras.ops.cast(values, dtype='int32')\n",
    "        tp = tf.keras.ops.sum(values).numpy()\n",
    "        \n",
    "        # Verifica a quantidade de VERDADEIROS NEGATIVOS (TN)\n",
    "        values = tf.keras.ops.logical_and(tf.keras.ops.equal(y_true, False), tf.keras.ops.equal(y_pred, False))\n",
    "        values = tf.keras.ops.cast(values, dtype='int32')\n",
    "        tn = tf.keras.ops.sum(values).numpy()\n",
    "        \n",
    "        # Verifica a quantidade de FALSO POSITIVO (FP)\n",
    "        values = tf.keras.ops.logical_and(tf.keras.ops.equal(y_true, False), tf.keras.ops.equal(y_pred, True))\n",
    "        values = tf.keras.ops.cast(values, dtype='int32')\n",
    "        fp = tf.keras.ops.sum(values).numpy()\n",
    "\n",
    "        # Verifica a quantidade de FALSO NEGATIVO (FN)\n",
    "        values = tf.keras.ops.logical_and(tf.keras.ops.equal(y_true, True), tf.keras.ops.equal(y_pred, False))\n",
    "        values = tf.keras.ops.cast(values, dtype='int32')\n",
    "        fn = tf.keras.ops.sum(values).numpy()\n",
    "\n",
    "        f1_1 = (2 * tp) / (2 * tp + fp + fn)\n",
    "        f1_0 = (2 * tn) / (2 * tn + fp + fn)\n",
    "\n",
    "        f = 0\n",
    "\n",
    "        if self.Tipo == 'macro':\n",
    "            f = (f1_1 + f1_0) / 2\n",
    "        elif self.Tipo == 'micro':\n",
    "            f = (tp + tn) / (tp + fp + fn + tn)\n",
    "        elif self.Tipo == 'weighted':\n",
    "            f = (((tp+fn) * f1_1) + ((fp + tn) * f1_0)) / ((tp+fn) + (fp + tn))\n",
    "            \n",
    "        self.f1.assign(f)\n",
    "\n",
    "    def result(self):\n",
    "        return self.f1\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.f1.assign(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criando a Métrica F1-Score Customizada (com parâmetro) usando Keras e Numpy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomF1ScoreN(tf.keras.metrics.Metric): \n",
    "    def __init__(self, name='f1', Tipo='macro'):\n",
    "        super(CustomF1ScoreN, self).__init__()\n",
    "        self.f1 = self.add_weight(name=name, initializer='zeros')\n",
    "        self.Tipo = Tipo\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "    \n",
    "        y_pred = np.reshape(np.round(y_pred), -1)\n",
    "        #y_true = np.reshape(y_true, shape=(-1, 1))\n",
    "\n",
    "        # Transforma o array/list de inteiros para booleano: [0,1,0,1] --> [False,  True, False,  True]\n",
    "        y_true = np.bool_(y_true)\n",
    "        y_pred = np.bool_(y_pred)\n",
    "\n",
    "        # Verifica a quantidade de VERDADEIROS POSITIVOS (TP)\n",
    "        values = np.logical_and(np.equal(y_true, True), np.equal(y_pred, True))\n",
    "        # Transforma o array/list de booleano para inteiro: [False,  True, False,  True] --> [0,1,0,1]\n",
    "        values = values.astype(int)  \n",
    "        # Faz a soma do array/list\n",
    "        tp = np.sum(values)\n",
    "        \n",
    "        # Verifica a quantidade de VERDADEIROS NEGATIVOS (TN)\n",
    "        values = np.logical_and(np.equal(y_true, False), np.equal(y_pred, False))\n",
    "        # Transforma o array/list de booleano para inteiro: [False,  True, False,  True] --> [0,1,0,1]\n",
    "        values = values.astype(int)  \n",
    "        # Faz a soma do array/list\n",
    "        tn = np.sum(values)\n",
    "\n",
    "        # Verifica a quantidade de FALSO POSITIVO (FP)\n",
    "        values = np.logical_and(np.equal(y_true, False), np.equal(y_pred, True))\n",
    "        # Transforma o array/list de booleano para inteiro: [False,  True, False,  True] --> [0,1,0,1]\n",
    "        values = values.astype(int)  \n",
    "        # Faz a soma do array/list\n",
    "        fp = np.sum(values)\n",
    "\n",
    "        # Verifica a quantidade de FALSO NEGATIVO (FN)\n",
    "        values = np.logical_and(np.equal(y_true, True), np.equal(y_pred, False))\n",
    "        # Transforma o array/list de booleano para inteiro: [False,  True, False,  True] --> [0,1,0,1]\n",
    "        values = values.astype(int)  \n",
    "        # Faz a soma do array/list\n",
    "        fn = np.sum(values)\n",
    "\n",
    "        f1_1 = (2 * tp) / (2 * tp + fp + fn)\n",
    "        f1_0 = (2 * tn) / (2 * tn + fp + fn)\n",
    "\n",
    "        \n",
    "        # cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        # tn, fp, fn, tp = cf_matrix.ravel()\n",
    "\n",
    "        f = 0\n",
    "\n",
    "        if self.Tipo == 'macro':\n",
    "            f = (f1_1 + f1_0) / 2\n",
    "        elif self.Tipo == 'micro':\n",
    "            f = (tp + tn) / (tp + fp + fn + tn)\n",
    "        elif self.Tipo == 'weighted':\n",
    "            f = (((tp+fn) * f1_1) + ((fp + tn) * f1_0)) / ((tp+fn) + (fp + tn))\n",
    "            \n",
    "        self.f1.assign(f)\n",
    "\n",
    "    def result(self):\n",
    "        return self.f1\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.f1.assign(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Métrica F1-Score Customizada (sem parâmetros) usando Keras e Scikit-Learn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class CustomF1Score_SP(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1-score-macro', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.f1_macro = self.add_weight(name='f1-macro', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        \n",
    "        y_pred_ = np.array(np.reshape(np.round(y_pred), -1), np.int32)\n",
    "\n",
    "        f1 = np.round(f1_score(y_true, y_pred_, average=\"macro\"), 2)\n",
    "\n",
    "        self.f1_macro.assign(f1)     \n",
    "\n",
    "    def result(self):\n",
    "        return self.f1_macro\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.f1_macro.assign(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Métrica Balanced Accuracy Customizada (sem parâmetros) usando Keras e Scikit-Learn**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A balanced_accuracy_score função calcula a precisão balanceada, o que evita estimativas de desempenho inflacionadas em conjuntos de dados desequilibrados. \n",
    "\n",
    "No caso binário, a precisão balanceada é igual à média aritmética de sensibilidade (taxa verdadeira positiva) e especificidade (taxa verdadeira negativa), ou a área sob a curva ROC com previsões binárias em vez de pontuações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "class CustomBalancedAccuracy(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='CustomBalancedAccuracy', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.balanced_acc = self.add_weight(name='Acc', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        \n",
    "        y_pred_ = np.array(np.reshape(np.round(y_pred), -1), np.int32)\n",
    "\n",
    "        bc = np.round(balanced_accuracy_score(y_true, y_pred_), 2) \n",
    "\n",
    "        self.balanced_acc.assign(bc)     \n",
    "\n",
    "    def result(self):\n",
    "        return self.balanced_acc\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.balanced_acc.assign(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Métrica Balanced Accuracy Customizada (sem parâmetros) usando Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBalancedAccuracyC(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='CustomBalancedAccuracy', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.balanced_acc = self.add_weight(name='Acc', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "    \n",
    "        y_pred = np.reshape(np.round(y_pred), -1)\n",
    "        #y_true = np.reshape(y_true, shape=(-1, 1))\n",
    "\n",
    "        # Transforma o array/list de inteiros para booleano: [0,1,0,1] --> [False,  True, False,  True]\n",
    "        y_true = np.bool_(y_true)\n",
    "        y_pred = np.bool_(y_pred)\n",
    "\n",
    "        # Verifica a quantidade de VERDADEIROS POSITIVOS (TP)\n",
    "        values = np.logical_and(np.equal(y_true, True), np.equal(y_pred, True))\n",
    "        # Transforma o array/list de booleano para inteiro: [False,  True, False,  True] --> [0,1,0,1]\n",
    "        values = values.astype(int)  \n",
    "        # Faz a soma do array/list\n",
    "        tp = np.sum(values)\n",
    "        \n",
    "        # Verifica a quantidade de VERDADEIROS NEGATIVOS (TN)\n",
    "        values = np.logical_and(np.equal(y_true, False), np.equal(y_pred, False))\n",
    "        # Transforma o array/list de booleano para inteiro: [False,  True, False,  True] --> [0,1,0,1]\n",
    "        values = values.astype(int)  \n",
    "        # Faz a soma do array/list\n",
    "        tn = np.sum(values)\n",
    "\n",
    "        # Verifica a quantidade de FALSO POSITIVO (FP)\n",
    "        values = np.logical_and(np.equal(y_true, False), np.equal(y_pred, True))\n",
    "        # Transforma o array/list de booleano para inteiro: [False,  True, False,  True] --> [0,1,0,1]\n",
    "        values = values.astype(int)  \n",
    "        # Faz a soma do array/list\n",
    "        fp = np.sum(values)\n",
    "\n",
    "        # Verifica a quantidade de FALSO NEGATIVO (FN)\n",
    "        values = np.logical_and(np.equal(y_true, True), np.equal(y_pred, False))\n",
    "        # Transforma o array/list de booleano para inteiro: [False,  True, False,  True] --> [0,1,0,1]\n",
    "        values = values.astype(int)  \n",
    "        # Faz a soma do array/list\n",
    "        fn = np.sum(values)\n",
    "\n",
    "        f = 1/2 * ((tp/(tp+fn)) + (tn/(tn+fp)))\n",
    "       \n",
    "        \n",
    "        # cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        # tn, fp, fn, tp = cf_matrix.ravel()\n",
    "\n",
    "        self.balanced_acc.assign(f)    \n",
    "\n",
    "    def result(self):\n",
    "        return self.balanced_acc\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.balanced_acc.assign(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Métrica Balanced Accuracy Customizada (com parâmetros) usando Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar limite de decisão para as probabilidades do modelo\n",
    "def to_labels(pos_probs, threshold):\n",
    "    return (pos_probs >= threshold).astype('int')\n",
    "\n",
    "\n",
    "class CustomBalancedAccuracy_CP(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='CustomBalancedAccuracy', Threshold=0):\n",
    "        super(CustomBalancedAccuracy_CP, self).__init__()\n",
    "        self.balanced_acc = self.add_weight(name='Acc', initializer='zeros')\n",
    "        self.Threshold = Threshold\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        \n",
    "        y_pred_ = np.reshape(y_pred, -1)\n",
    "\n",
    "        f1 = np.round(balanced_accuracy_score(y_true, to_labels(y_pred_, self.Threshold)), 2)\n",
    "        \n",
    "        self.balanced_acc.assign(f1)  \n",
    "\n",
    "    def result(self):\n",
    "        return self.balanced_acc\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.balanced_acc.assign(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construindo o Modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O formato de entrada é a contagem vocabulário usados pelas avaliações dos filmes (10000 palavras)\n",
    "vocab_size = 10000\n",
    "max_length = 16\n",
    "\n",
    "# Configurando a arquitetura do modelo  \n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# --> Camada de Entrada\n",
    "# Geralmente, todas as camadas no Keras precisam conhecer a forma de suas entradas para poder criar seus pesos\n",
    "# Neste caso, você deve iniciar seu modelo passando um objeto Input para seu modelo, para que ele conheça sua forma de entrada desde o início\n",
    "# Modelos construídos com um formato de entrada predefinido como esse sempre possuem pesos (mesmo antes de ver qualquer dado) e sempre possuem um formato de saída definido.\n",
    "# Em geral, é uma prática recomendada sempre especificar antecipadamente o formato de entrada de um modelo Sequencial, se você souber o que é.\n",
    "# Uma alternativa simples é apenas passar um argumento input_shape para sua primeira camada:\n",
    "# Exemplo: model.add(tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=max_length, input_shape=(max_length,)))\n",
    "# No entanto, o exemplo acima gera um warning: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
    "# https://keras.io/guides/sequential_model/\n",
    "# https://www.tensorflow.org/guide/keras/sequential_model?hl=pt-br\n",
    "model.add(tf.keras.Input(shape=(max_length,)))\n",
    "\n",
    "# Adicionando Camada de Incorporação - Transforma inteiros positivos (índices) em vetores densos de tamanho fixo.\n",
    "model.add(tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=max_length))\n",
    "\n",
    "# --> Camadas Intermediárias\n",
    "# Adicionando Camada de Convolução\n",
    "model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "\n",
    "# Adicionando Camada de Pooling\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "                            \n",
    "# Adicionando Camada Totalmente Conectada\n",
    "model.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(rate=0.30))\n",
    "\n",
    "# --> Camada de Saída                 \n",
    "model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Sumário do modelo\n",
    "#model.summary()\n",
    "\n",
    "# Configurando o modelo para treinamento\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(name='adam', learning_rate=0.001),   # O learning_rate padrão é 0.001 \n",
    "                # Já que é um problema de classificação binário e o modelo tem como saída uma probabilidade usaremos a função loss \"binary_crossentropy\". A binary_crossentropy é a melhor função de loss para tratar probabilidades— ela mede a \"distância\" entre as distribuições de probabilidade, ou, no nosso caso, sobre a distribuição real e as previsões.\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(name='binary_crossentropy'), \n",
    "                # Usaremos como métrica a binary_accuracy. Essa métrica é utilizada especificamente em problemas de classificação binária e calcula com que frequência as previsões correspondem aos rótulos binários.\n",
    "                metrics=[CustomF1ScoreA()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 321ms/step - f1-score-macro: 0.4821 - loss: 0.6926 - val_f1-score-macro: 0.7165 - val_loss: 0.6836\n",
      "Epoch 2/2\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 352ms/step - f1-score-macro: 0.7049 - loss: 0.6575 - val_f1-score-macro: 0.7469 - val_loss: 0.5494\n"
     ]
    }
   ],
   "source": [
    "# Treinando o modelo\n",
    "history = model.fit(x=X_train,\n",
    "                    y=y_train,\n",
    "                    epochs=2,\n",
    "                    batch_size=512,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step\n",
      "73.0\n"
     ]
    }
   ],
   "source": [
    "m = CustomF1ScoreA()\n",
    "m.update_state(test_labels, model.predict(test_data))\n",
    "f1_1 = tf.keras.ops.round(tf.convert_to_tensor(m.result().numpy(), dtype=tf.float64), 2)*100\n",
    "\n",
    "print(f'{f1_1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step\n",
      "74.0 73.0 73.0\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step\n",
      "0.74 0.73 0.73\n"
     ]
    }
   ],
   "source": [
    "m = CustomF1ScoreB(Tipo='micro')\n",
    "m.update_state(test_labels, model.predict(test_data))\n",
    "f1_1 = tf.keras.ops.round(tf.convert_to_tensor(m.result().numpy(), dtype=tf.float64), 2)*100\n",
    "\n",
    "m = CustomF1ScoreB(Tipo='macro')\n",
    "m.update_state(test_labels, model.predict(test_data))\n",
    "f1_2 = tf.keras.ops.round(tf.convert_to_tensor(m.result().numpy(), dtype=tf.float64), 2)*100\n",
    "\n",
    "m = CustomF1ScoreB(Tipo='weighted')\n",
    "m.update_state(test_labels, model.predict(test_data))\n",
    "f1_3 = tf.keras.ops.round(tf.convert_to_tensor(m.result().numpy(), dtype=tf.float64), 2)*100\n",
    "\n",
    "print(f'{f1_1} {f1_2} {f1_3}')\n",
    "\n",
    "y_pred_ = np.array(np.reshape(np.round(model.predict(test_data)), -1), np.int32)\n",
    "c_test_1 = np.round(f1_score(test_labels, y_pred_, average='micro'), 2)\n",
    "\n",
    "y_pred_ = np.array(np.reshape(np.round(model.predict(test_data)), -1), np.int32)\n",
    "c_test_2 = np.round(f1_score(test_labels, y_pred_, average='macro'), 2)\n",
    "\n",
    "y_pred_ = np.array(np.reshape(np.round(model.predict(test_data)), -1), np.int32)\n",
    "c_test_3 = np.round(f1_score(test_labels, y_pred_, average='weighted'), 2)\n",
    "\n",
    "print(f'{c_test_1} {c_test_2} {c_test_3}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step\n",
      "74.0 73.0 73.0\n"
     ]
    }
   ],
   "source": [
    "m = CustomF1ScoreN(Tipo='micro')\n",
    "m.update_state(test_labels, model.predict(test_data))\n",
    "f1_1 = tf.keras.ops.round(tf.convert_to_tensor(m.result().numpy(), dtype=tf.float64), 2)*100\n",
    "\n",
    "m = CustomF1ScoreN(Tipo='macro')\n",
    "m.update_state(test_labels, model.predict(test_data))\n",
    "f1_2 = tf.keras.ops.round(tf.convert_to_tensor(m.result().numpy(), dtype=tf.float64), 2)*100\n",
    "\n",
    "m = CustomF1ScoreN(Tipo='weighted')\n",
    "m.update_state(test_labels, model.predict(test_data))\n",
    "f1_3 = tf.keras.ops.round(tf.convert_to_tensor(m.result().numpy(), dtype=tf.float64), 2)*100\n",
    "\n",
    "print(f'{f1_1} {f1_2} {f1_3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step\n",
      "73.0\n"
     ]
    }
   ],
   "source": [
    "m = CustomF1Score_SP()\n",
    "m.update_state(test_labels, model.predict(test_data))\n",
    "f1_0 = tf.keras.ops.round(tf.convert_to_tensor(m.result().numpy(), dtype=tf.float64), 2)*100\n",
    "\n",
    "print(f'{f1_0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step\n",
      "74.0 74.0 67.0 0.74\n"
     ]
    }
   ],
   "source": [
    "c = CustomBalancedAccuracy()\n",
    "c.update_state(test_labels, model.predict(test_data))\n",
    "c_test_1 = tf.keras.ops.round(tf.convert_to_tensor(c.result().numpy(), dtype=tf.float64), 2)*100\n",
    "\n",
    "c = CustomBalancedAccuracyC()\n",
    "c.update_state(test_labels, model.predict(test_data))\n",
    "c_test_2 = tf.keras.ops.round(tf.convert_to_tensor(c.result().numpy(), dtype=tf.float64), 2)*100\n",
    "\n",
    "c = CustomBalancedAccuracy_CP(Threshold=0.356)\n",
    "c.update_state(test_labels, model.predict(test_data))\n",
    "c_test_3 = tf.keras.ops.round(tf.convert_to_tensor(c.result().numpy(), dtype=tf.float64), 2)*100\n",
    "\n",
    "y_pred_ = np.array(np.reshape(np.round(model.predict(test_data)), -1), np.int32)\n",
    "c_test_4 = np.round(balanced_accuracy_score(test_labels, y_pred_), 2)\n",
    "\n",
    "print(f'{c_test_1} {c_test_2} {c_test_3} {c_test_4}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
